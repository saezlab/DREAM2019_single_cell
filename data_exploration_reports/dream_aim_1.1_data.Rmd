---
title: "DREAM AIM I data"
author: "Attila Gabor"
date: "4/26/2019"
output: html_document
---


```{r include=FALSE}
library(tidyverse)
library(DBI)
library(RSQLite)
library(progress)
```
# Median data interpolation
the code will skip this section and data is read from the disk. 

Load the median data to find suitable cell-lines
```{r,eval=FALSE}
median_data <- read_rds("./data/median_data/median_all_reporters_mine.rds") %>% as_tibble()
```
preparing time-courses:
we interpolate the data to the same timepoints:

```{r,eval=FALSE}
# uncomment if we use Marco's data
# median_data <- median_data %>% mutate(time = as.character(time)) %>%
# 	mutate(time = ifelse(time=="0short","0",time)) %>%
# 	mutate(time = ifelse(is.na(time),"0",time)) %>%
# 	mutate(time = as.numeric(as.character(time))) 

median_data%>%pull(time) %>% table()
base_time = c(0,5.5,7,9,13,17,23,30,40,60)
```
In case of Marco's median data interpolation in 2 steps:
1. interpolate for the basal time per time_course
 - first we filter out treatment full, because that has only time 0 so we dont want to interpolate.
 - for each reporter time_course we interpolate for the base_timepoints, defined above
2. interpolate (average) between the time_courses

```{r,eval=FALSE}
median_interpolated_data = median_data %>% select(-`dmt$cellcount`) %>% filter(treatment != "full") %>%
	gather(reporter,value,-cell_line,-treatment,-time,-time_course) %>%
	group_by(cell_line,treatment,time_course,reporter) %>% # interpolating per time_course!
	nest() %>%
	mutate(interp_value = map(data, function(data){
	
		out = approx(x = data$time,y = data$value,xout = base_time,method ="linear",rule = 2)
		data.frame(time=out$x,value=out$y)
	}
		))%>% unnest(interp_value) %>%
	# bind the EGF treatment: this has only time 0
	bind_rows( median_data %>% select(-`dmt$cellcount`) %>%
			   	filter(treatment == "full") %>%
			   	gather(reporter,value,-cell_line,-treatment,-time,-time_course)  
			   ) %>%

	group_by(cell_line,treatment,time,reporter) %>% # averaging over time_course!
	summarise(value = mean(value))

if(FALSE) saveRDS(median_interpolated_data,"./data/median_data/interpolated_median_allsamples_nocontrols_withcellcount.rds")
```


My data: time is already handled, but average over the fileID

- remove temporarly the full treatment --> no time course
- averageing over FileID can be tricky, because replicates
- average the value for each condition (cellline/treatment/time/reporter)

```{r,eval=FALSE}
median_interpolated_data = median_data %>% filter(treatment != "full") %>%  
	gather(reporter,value,-cell_line,-treatment,-time,-fileID) %>%
	group_by(cell_line,treatment,time,reporter) %>%
	summarise(value = mean(value, na.rm = TRUE)) %>%  # average in each condition over fileID
	ungroup() %>%
	group_by(cell_line,treatment,reporter) %>% # interpolating in time
	nest() %>%
	mutate(interp_value = map(data, function(data){
		#browser()
		if(sum(!is.na(data$value))<2) {
			# TODO: if there is 1 numeric value we throw it away
		 	out = data.frame(time=base_time,value=NA)
		 	return(out)
		 }
		out = approx(x = data$time,y = data$value,xout = base_time,method ="linear",rule = 2)
		data.frame(time=out$x,value=out$y)
	}
	))%>% unnest(interp_value) %>%
	# bind the EGF treatment: this has only time 0
	bind_rows( median_data %>% 
			   	filter(treatment == "full") %>%
			   	gather(reporter,value,-cell_line,-treatment,-time, -fileID) %>%
			group_by(cell_line,treatment,time,reporter) %>% 
			summarise(value = mean(value, na.rm = TRUE) ) # mean over fileID
			   	
	) %>%
	ungroup() 

if(FALSE) write_rds(median_interpolated_data,"./data/median_data/interpolated_median_all_reporters_mine.rds")
```

### Load the interpolated data

```{r}
median_interpolated_data <- read_rds("./data/median_data/interpolated_median_all_reporters_mine.rds")
```

# Clustering cell-lines

- remove the cell-lines with missing HER2/plcg values --> prevent the clustering and 
they cannot be used to train or validate the models in AIM 1.1
```{r clean_na }
median_interpolated_data %>% filter(reporter =="p.HER2") %>% filter(is.na(value)) %>% 
	mutate(value  = 1) %>%
	spread(cell_line,value, drop=FALSE)

```

The first approach: use all reporters
```{r,fig.height=7,fig.width=7}
NA_celllines = median_interpolated_data %>% filter(is.na(value)) %>% pull(cell_line) %>% unique()

# heatmap data ----
hm_data_whole <- median_interpolated_data %>% 
	filter(! cell_line %in% NA_celllines ) %>%
	mutate(row_description = paste(reporter, treatment,time,sep = "_")) %>%
	ungroup()%>%
	select(row_description,cell_line,value) %>%
	spread(cell_line,value = value) %>%
	column_to_rownames("row_description") 

# annotation work ----
row_labeling_whole = tibble(original_names = rownames(hm_data_whole)) %>%
	mutate(label = ifelse(grepl("EGF_0",original_names),original_names,""))


ph_obj = hm_data_whole %>% pheatmap(cluster_rows = F, clustering_distance_cols = "euclidean", labels_row = row_labeling_whole$label, cutree_cols = 12) 



col_annotation_whole = data.frame(global_groups = as.factor(cutree(ph_obj$tree_col,k = 12)))

ph_obj = hm_data_whole %>% pheatmap(cluster_rows = F, clustering_distance_cols = "euclidean", labels_row = row_labeling_whole$label, cutree_cols = 12,annotation_col =col_annotation_whole )

```



In the second approach we select only the reporters that we ask for prediction 

```{r,fig.width=10}
# heatmap data ----
NA_celllines = median_interpolated_data %>% filter(is.na(value)) %>% pull(cell_line) %>% unique()

hm_data <- median_interpolated_data %>% 
	filter(! cell_line %in% NA_celllines ) %>%
	filter(reporter %in% c("p.ERK","p.Akt.Ser473.","p.S6","p.PLCg2","p.HER2"))%>%
	mutate(row_description = paste(reporter, treatment,time,sep = "_")) %>%
	ungroup()%>%
	select(row_description,cell_line,value) %>%
	spread(cell_line,value = value) %>%
	column_to_rownames("row_description") 


# annotation work ----
# this was the old selection
#training_celllines = setdiff(c('AU565','BT483','CAL148', 'SKBR3','HBL100', 'HCC2185','MCF10A'),NA_celllines)
#test_celllines = setdiff(c('T47D','HCC1806','HCC2218', 'HCC70','UACC893'),NA_celllines)

#cell_lines = median_interpolated_data %>% pull(cell_line) %>% unique() %>% as.character()
# 
# col_annotation = data.frame(cell_lines)%>% 
# 	mutate(purpose = ifelse(cell_lines %in%  training_celllines, "training",
# 							ifelse(cell_lines %in% test_celllines,"test","not_selected"))) %>%
# 	column_to_rownames("cell_lines")
# 
# ann_colors = list(purpose = c(training="green",test="red",not_selected="white"))

col_annotation <- col_annotation_whole%>% rownames_to_column("cell_line") %>% mutate(global_groups = ifelse(global_groups %in% c(1,2,3,4,7,8,10),global_groups,"-")) %>% column_to_rownames("cell_line")



row_labeling = tibble(original_names = rownames(hm_data)) %>%
	mutate(label = ifelse(grepl("_0",original_names),original_names,""))

# plotting -----
library(pheatmap)



hm_data %>% pheatmap(cluster_rows = F,annotation_col = col_annotation, clustering_distance_cols = "euclidean", labels_row = row_labeling$label, cutree_cols = 7) 
```


# Number of distinct clusters
we dont need this. 
```{r, eval=FALSE}
#install.packages("NbClust")
library(NbClust)
```
```{r, eval = FALSE}
nb_res <- NbClust(data = hm_data, distance = "euclidean", min.nc = 3, max.nc = 10, method = "complete", index = "alllong")
```

